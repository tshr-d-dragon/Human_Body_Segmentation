{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awYguTDau9c5",
    "outputId": "8ac02505-7caa-4b0b-8578-b658d2e3fdd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 19 07:48:33 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "1SCGf_0Mu9Zq",
    "outputId": "47e9c4e9-3170-4782-9ec8-7076037a7cd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a49c8969-539c-47fc-a50a-23f4bf105d15\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a49c8969-539c-47fc-a50a-23f4bf105d15\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "kaggle.json\n",
      "Downloading supervisely-filtered-segmentation-person-dataset.zip to /content\n",
      "100% 4.30G/4.31G [01:24<00:00, 25.6MB/s]\n",
      "100% 4.31G/4.31G [01:24<00:00, 54.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload() #upload kaggle.json\n",
    "\n",
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d tapakah68/supervisely-filtered-segmentation-person-dataset\n",
    "\n",
    "!unzip -q /content/supervisely-filtered-segmentation-person-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHn0aCfRu9Xw",
    "outputId": "7a032c50-a993-4819-ab75-68e70d2deaa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting q\n",
      "  Downloading https://files.pythonhosted.org/packages/53/bc/51619d89e0bd855567e7652fa16d06f1ed36a85f108a7fe71f6629bf719d/q-2.6-py2.py3-none-any.whl\n",
      "Collecting tensorflow==2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/56/0dbdae2a3c527a119bec0d5cf441655fe030ce1daa6fa6b9542f7dbd8664/tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 16kB/s \n",
      "\u001b[?25hCollecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.19.5)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 37.7MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 53.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.34.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.36.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.15.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (3.17.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.32.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (57.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.23.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1) (3.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.10)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1) (1.5.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.7.4.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.8)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=57f999de125516d13167b908d0ceed1d760872063f0a3734061c8dcb981ad332\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow-probability 0.13.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: q, gast, tensorboard, tensorflow-estimator, keras-applications, tensorflow\n",
      "  Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "Successfully installed gast-0.2.2 keras-applications-1.0.8 q-2.6 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
      "Requirement already satisfied: q in /usr/local/lib/python3.7/dist-packages (2.6)\n",
      "Collecting keras==2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 19.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.3.1\n",
      "Collecting git+https://github.com/qubvel/segmentation_models\n",
      "  Cloning https://github.com/qubvel/segmentation_models to /tmp/pip-req-build-5_c2sb23\n",
      "  Running command git clone -q https://github.com/qubvel/segmentation_models /tmp/pip-req-build-5_c2sb23\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models==1.0.1) (1.0.8)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
      "Collecting efficientnet==1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.19.5)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.16.2)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.5.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.4.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.2.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.5.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (7.1.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.8.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (4.4.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.15.0)\n",
      "Building wheels for collected packages: segmentation-models\n",
      "  Building wheel for segmentation-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segmentation-models: filename=segmentation_models-1.0.1-cp37-none-any.whl size=33810 sha256=024a5b328e400acd8b4318ac6bfcfd2ab8146182a7ef054a8610e7ae0bd00ada\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-aqw79525/wheels/49/cf/46/cbb4bb64518c402aea99df9d466f1081450597e653256bbcf4\n",
      "Successfully built segmentation-models\n",
      "Installing collected packages: image-classifiers, efficientnet, segmentation-models\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n",
      "Uninstalling h5py-3.1.0:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.7/dist-packages/h5py-3.1.0.dist-info/*\n",
      "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libaec-9c9e97eb.so.0.0.10\n",
      "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5-00e8fae8.so.200.0.0\n",
      "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5_hl-383c339f.so.200.0.0\n",
      "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libsz-e7aa62f5.so.2.0.1\n",
      "    /usr/local/lib/python3.7/dist-packages/h5py.libs/libz-eb09ad1d.so.1.2.3\n",
      "    /usr/local/lib/python3.7/dist-packages/h5py/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled h5py-3.1.0\n",
      "Collecting h5py==2.10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 29.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-2.10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install q tensorflow==2.1\n",
    "!pip install q keras==2.3.1\n",
    "!pip install git+https://github.com/qubvel/segmentation_models\n",
    "\n",
    "# for str decode error ... run it and restart runtime\n",
    "!pip uninstall h5py\n",
    "!pip install h5py==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9AiILAju9VE",
    "outputId": "7c70f2db-20b3-4f3d-e832-cb6a52234c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133 2133 534 534\n",
      "(16, 512, 512, 3) (16, 512, 512, 1)\n",
      "(16, 512, 512, 3) (16, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    images = glob(os.path.join(dataset_path, \"images/*\"))\n",
    "    masks = glob(os.path.join(dataset_path, \"masks/*\"))\n",
    "\n",
    "    train_x, test_x = train_test_split(images, test_size=0.2, random_state=1996)\n",
    "    train_y, test_y = train_test_split(masks, test_size=0.2, random_state=1996)\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = load_dataset('/content/supervisely_person_clean_2667_img')\n",
    "print(len(train_x), len(train_y), len(test_x), len(test_y))\n",
    "\n",
    "train_X_y_paths = list(zip(train_x, train_y))\n",
    "val_X_y_paths = list(zip(test_x, test_y))\n",
    "\n",
    "def shuffle(samples):\n",
    "  index = np.random.permutation(len(samples))\n",
    "  return np.array(samples)[index]\n",
    "\n",
    "# def get_data(base_dir,w):\n",
    "#   img = glob(base_dir+f'images/{w}/*/*.png')\n",
    "#   img_names = [path.split(f'/{w}/')[1].split('_leftImg8bit.png')[0] for path in img]\n",
    "#   label = [base_dir + f'gtFine/{w}/' + name + '_gtFine_color.png' for name in img_names]\n",
    "#   del img_names\n",
    "#   return img, label\n",
    "\n",
    "# base_dir = \"/content/people_segmentation\"\n",
    "# train_img,train_label = pre_shuffle(*get_data(base_dir,\"images\"))\n",
    "# val_img,val_label = pre_shuffle(*get_data(base_dir,\"val\"))\n",
    "\n",
    "def get_data_generator(samples,batch_size):\n",
    "\n",
    "  while True:\n",
    "    for offset in range(0, len(samples), batch_size): \n",
    "      samples = shuffle(samples)           \n",
    "      batch_samples = samples[offset:offset+batch_size]\n",
    "      X_train = []\n",
    "      Y_train = []        \n",
    " \n",
    "      for batch_sample in batch_samples:\n",
    "          \n",
    "        X_image = cv2.imread(batch_sample[0])[:,:,::-1]# convert bgr to rgb\n",
    "        X_image = cv2.resize(X_image, (512, 512))\n",
    "        X_image = X_image / 255.0\n",
    "        X_image = X_image.astype(np.float32)\n",
    "\n",
    "        Y_image = cv2.imread(batch_sample[1], 0)\n",
    "#         Y_image = Y_image * 255.0\n",
    "        Y_image = cv2.resize(Y_image, (512, 512))\n",
    "        Y_image = Y_image / 255.0\n",
    "        Y_image = Y_image.astype(np.float32)\n",
    "        Y_image = np.expand_dims(Y_image, axis=-1)\n",
    "\n",
    "        X_train.append(X_image)\n",
    "        Y_train.append(Y_image)\n",
    "      yield np.array(X_train), np.array(Y_train)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_generator = get_data_generator(train_X_y_paths,batch_size=BATCH_SIZE)\n",
    "val_generator = get_data_generator(val_X_y_paths,batch_size=BATCH_SIZE)\n",
    " \n",
    "x_train, y_train = next(train_generator)\n",
    "x_val, y_val  = next(val_generator)\n",
    " \n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPGMAWRUu9Sf",
    "outputId": "274a0413-8ba2-480e-88ea-8e4b43a3b08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "267 67\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 267 steps, validate for 67 steps\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 529s 2s/step - loss: 1.4936 - precision: 0.5663 - recall: 0.6662 - f1-score: 0.6069 - iou_score: 0.4404 - val_loss: 4.0646 - val_precision: 0.4458 - val_recall: 0.0037 - val_f1-score: 0.0072 - val_iou_score: 0.0036\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 520s 2s/step - loss: 1.1611 - precision: 0.6799 - recall: 0.7476 - f1-score: 0.7078 - iou_score: 0.5495 - val_loss: 4.4901 - val_precision: 0.3791 - val_recall: 0.9669 - val_f1-score: 0.5422 - val_iou_score: 0.3739\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 513s 2s/step - loss: 1.0136 - precision: 0.7304 - recall: 0.7833 - f1-score: 0.7511 - iou_score: 0.6032 - val_loss: 2.0297 - val_precision: 0.4137 - val_recall: 0.4340 - val_f1-score: 0.4206 - val_iou_score: 0.2671\n",
      "Epoch 4/100\n",
      "267/267 [==============================] - 521s 2s/step - loss: 0.8613 - precision: 0.7762 - recall: 0.8180 - f1-score: 0.7933 - iou_score: 0.6590 - val_loss: 3.4767 - val_precision: 0.3654 - val_recall: 0.9655 - val_f1-score: 0.5277 - val_iou_score: 0.3605\n",
      "Epoch 5/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.8065 - precision: 0.7919 - recall: 0.8331 - f1-score: 0.8084 - iou_score: 0.6803\n",
      "Epoch 00005: saving model to /content/Deeplabv3p_MobilenetV2_Human_Seg_000+5.h5\n",
      "267/267 [==============================] - 516s 2s/step - loss: 0.8059 - precision: 0.7922 - recall: 0.8332 - f1-score: 0.8086 - iou_score: 0.6805 - val_loss: 1.8562 - val_precision: 0.4969 - val_recall: 0.5952 - val_f1-score: 0.5379 - val_iou_score: 0.3690\n",
      "Epoch 6/100\n",
      "267/267 [==============================] - 522s 2s/step - loss: 0.7066 - precision: 0.8210 - recall: 0.8535 - f1-score: 0.8340 - iou_score: 0.7172 - val_loss: 1.9646 - val_precision: 0.5242 - val_recall: 0.7042 - val_f1-score: 0.5977 - val_iou_score: 0.4282\n",
      "Epoch 7/100\n",
      "267/267 [==============================] - 496s 2s/step - loss: 0.6663 - precision: 0.8334 - recall: 0.8634 - f1-score: 0.8451 - iou_score: 0.7336 - val_loss: 1.6818 - val_precision: 0.5851 - val_recall: 0.6758 - val_f1-score: 0.6244 - val_iou_score: 0.4558\n",
      "Epoch 8/100\n",
      "267/267 [==============================] - 510s 2s/step - loss: 0.6492 - precision: 0.8371 - recall: 0.8668 - f1-score: 0.8490 - iou_score: 0.7392 - val_loss: 2.3305 - val_precision: 0.6221 - val_recall: 0.4208 - val_f1-score: 0.4981 - val_iou_score: 0.3335\n",
      "Epoch 9/100\n",
      "267/267 [==============================] - 532s 2s/step - loss: 0.5863 - precision: 0.8546 - recall: 0.8811 - f1-score: 0.8650 - iou_score: 0.7636 - val_loss: 1.5608 - val_precision: 0.6783 - val_recall: 0.7235 - val_f1-score: 0.6965 - val_iou_score: 0.5362\n",
      "Epoch 10/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.5491 - precision: 0.8651 - recall: 0.8891 - f1-score: 0.8746 - iou_score: 0.7786\n",
      "Epoch 00010: saving model to /content/Deeplabv3p_MobilenetV2_Human_Seg_000+10.h5\n",
      "267/267 [==============================] - 511s 2s/step - loss: 0.5494 - precision: 0.8653 - recall: 0.8888 - f1-score: 0.8745 - iou_score: 0.7785 - val_loss: 1.9607 - val_precision: 0.6906 - val_recall: 0.7059 - val_f1-score: 0.6957 - val_iou_score: 0.5354\n",
      "Epoch 11/100\n",
      "267/267 [==============================] - 507s 2s/step - loss: 0.5245 - precision: 0.8720 - recall: 0.8933 - f1-score: 0.8804 - iou_score: 0.7874 - val_loss: 2.2249 - val_precision: 0.6883 - val_recall: 0.5329 - val_f1-score: 0.5982 - val_iou_score: 0.4287\n",
      "Epoch 12/100\n",
      "267/267 [==============================] - 524s 2s/step - loss: 0.4935 - precision: 0.8788 - recall: 0.9017 - f1-score: 0.8882 - iou_score: 0.8002 - val_loss: 2.5612 - val_precision: 0.5838 - val_recall: 0.7724 - val_f1-score: 0.6615 - val_iou_score: 0.4971\n",
      "Epoch 13/100\n",
      "267/267 [==============================] - 536s 2s/step - loss: 0.4960 - precision: 0.8764 - recall: 0.9009 - f1-score: 0.8869 - iou_score: 0.7981 - val_loss: 3.3614 - val_precision: 0.5001 - val_recall: 0.8994 - val_f1-score: 0.6379 - val_iou_score: 0.4719\n",
      "Epoch 14/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.4937 - precision: 0.8783 - recall: 0.9003 - f1-score: 0.8873 - iou_score: 0.7989\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "267/267 [==============================] - 502s 2s/step - loss: 0.4937 - precision: 0.8786 - recall: 0.8999 - f1-score: 0.8873 - iou_score: 0.7989 - val_loss: 2.9259 - val_precision: 0.7396 - val_recall: 0.3825 - val_f1-score: 0.5007 - val_iou_score: 0.3356\n",
      "Epoch 15/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.3945 - precision: 0.9043 - recall: 0.9194 - f1-score: 0.9108 - iou_score: 0.8370\n",
      "Epoch 00015: saving model to /content/Deeplabv3p_MobilenetV2_Human_Seg_000+15.h5\n",
      "267/267 [==============================] - 515s 2s/step - loss: 0.3947 - precision: 0.9045 - recall: 0.9193 - f1-score: 0.9108 - iou_score: 0.8370 - val_loss: 1.4073 - val_precision: 0.6839 - val_recall: 0.7940 - val_f1-score: 0.7316 - val_iou_score: 0.5788\n",
      "Epoch 16/100\n",
      "267/267 [==============================] - 509s 2s/step - loss: 0.3420 - precision: 0.9160 - recall: 0.9315 - f1-score: 0.9230 - iou_score: 0.8576 - val_loss: 0.9995 - val_precision: 0.7539 - val_recall: 0.8315 - val_f1-score: 0.7874 - val_iou_score: 0.6526\n",
      "Epoch 17/100\n",
      "267/267 [==============================] - 503s 2s/step - loss: 0.3281 - precision: 0.9198 - recall: 0.9352 - f1-score: 0.9267 - iou_score: 0.8641 - val_loss: 0.7073 - val_precision: 0.8429 - val_recall: 0.8433 - val_f1-score: 0.8420 - val_iou_score: 0.7286\n",
      "Epoch 18/100\n",
      "267/267 [==============================] - 518s 2s/step - loss: 0.3109 - precision: 0.9244 - recall: 0.9387 - f1-score: 0.9309 - iou_score: 0.8712 - val_loss: 0.6047 - val_precision: 0.8737 - val_recall: 0.8571 - val_f1-score: 0.8645 - val_iou_score: 0.7629\n",
      "Epoch 19/100\n",
      "267/267 [==============================] - 512s 2s/step - loss: 0.2984 - precision: 0.9272 - recall: 0.9403 - f1-score: 0.9332 - iou_score: 0.8753 - val_loss: 0.5080 - val_precision: 0.8952 - val_recall: 0.8808 - val_f1-score: 0.8872 - val_iou_score: 0.7984\n",
      "Epoch 20/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.2755 - precision: 0.9331 - recall: 0.9453 - f1-score: 0.9388 - iou_score: 0.8850\n",
      "Epoch 00020: saving model to /content/Deeplabv3p_MobilenetV2_Human_Seg_000+20.h5\n",
      "267/267 [==============================] - 516s 2s/step - loss: 0.2753 - precision: 0.9331 - recall: 0.9453 - f1-score: 0.9388 - iou_score: 0.8851 - val_loss: 0.4768 - val_precision: 0.8773 - val_recall: 0.9074 - val_f1-score: 0.8915 - val_iou_score: 0.8052\n",
      "Epoch 21/100\n",
      "267/267 [==============================] - 511s 2s/step - loss: 0.2680 - precision: 0.9353 - recall: 0.9465 - f1-score: 0.9406 - iou_score: 0.8881 - val_loss: 0.4590 - val_precision: 0.8763 - val_recall: 0.9240 - val_f1-score: 0.8989 - val_iou_score: 0.8174\n",
      "Epoch 22/100\n",
      "267/267 [==============================] - 517s 2s/step - loss: 0.2589 - precision: 0.9380 - recall: 0.9485 - f1-score: 0.9429 - iou_score: 0.8924 - val_loss: 0.5069 - val_precision: 0.8790 - val_recall: 0.9015 - val_f1-score: 0.8890 - val_iou_score: 0.8013\n",
      "Epoch 23/100\n",
      "267/267 [==============================] - 517s 2s/step - loss: 0.2425 - precision: 0.9417 - recall: 0.9524 - f1-score: 0.9468 - iou_score: 0.8992 - val_loss: 0.4559 - val_precision: 0.9038 - val_recall: 0.8989 - val_f1-score: 0.9007 - val_iou_score: 0.8204\n",
      "Epoch 24/100\n",
      "267/267 [==============================] - 529s 2s/step - loss: 0.2375 - precision: 0.9430 - recall: 0.9525 - f1-score: 0.9475 - iou_score: 0.9005 - val_loss: 0.4308 - val_precision: 0.8864 - val_recall: 0.9275 - val_f1-score: 0.9058 - val_iou_score: 0.8288\n",
      "Epoch 25/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.2282 - precision: 0.9453 - recall: 0.9552 - f1-score: 0.9500 - iou_score: 0.9050\n",
      "Epoch 00025: saving model to /content/Deeplabv3p_MobilenetV2_Human_Seg_000+25.h5\n",
      "267/267 [==============================] - 513s 2s/step - loss: 0.2280 - precision: 0.9454 - recall: 0.9552 - f1-score: 0.9501 - iou_score: 0.9051 - val_loss: 0.4487 - val_precision: 0.8830 - val_recall: 0.9247 - val_f1-score: 0.9028 - val_iou_score: 0.8241\n",
      "Epoch 26/100\n",
      "267/267 [==============================] - 513s 2s/step - loss: 0.2238 - precision: 0.9464 - recall: 0.9556 - f1-score: 0.9508 - iou_score: 0.9065 - val_loss: 0.4857 - val_precision: 0.8739 - val_recall: 0.9179 - val_f1-score: 0.8943 - val_iou_score: 0.8106\n",
      "Epoch 27/100\n",
      "267/267 [==============================] - 516s 2s/step - loss: 0.2104 - precision: 0.9497 - recall: 0.9583 - f1-score: 0.9538 - iou_score: 0.9119 - val_loss: 0.4574 - val_precision: 0.9170 - val_recall: 0.8897 - val_f1-score: 0.9025 - val_iou_score: 0.8237\n",
      "Epoch 28/100\n",
      "267/267 [==============================] - 512s 2s/step - loss: 0.2065 - precision: 0.9513 - recall: 0.9586 - f1-score: 0.9548 - iou_score: 0.9138 - val_loss: 0.4807 - val_precision: 0.8924 - val_recall: 0.9084 - val_f1-score: 0.8996 - val_iou_score: 0.8191\n",
      "Epoch 29/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.1974 - precision: 0.9535 - recall: 0.9605 - f1-score: 0.9569 - iou_score: 0.9175\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "267/267 [==============================] - 514s 2s/step - loss: 0.1973 - precision: 0.9535 - recall: 0.9606 - f1-score: 0.9569 - iou_score: 0.9176 - val_loss: 0.4867 - val_precision: 0.8813 - val_recall: 0.9215 - val_f1-score: 0.9001 - val_iou_score: 0.8197\n",
      "Epoch 30/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.1901 - precision: 0.9548 - recall: 0.9623 - f1-score: 0.9584 - iou_score: 0.9204\n",
      "Epoch 00030: saving model to /content/Deeplabv3p_MobilenetV2_Human_Seg_000+30.h5\n",
      "267/267 [==============================] - 533s 2s/step - loss: 0.1899 - precision: 0.9548 - recall: 0.9624 - f1-score: 0.9585 - iou_score: 0.9204 - val_loss: 0.4342 - val_precision: 0.8919 - val_recall: 0.9287 - val_f1-score: 0.9092 - val_iou_score: 0.8345\n",
      "Epoch 31/100\n",
      "267/267 [==============================] - 519s 2s/step - loss: 0.1841 - precision: 0.9562 - recall: 0.9634 - f1-score: 0.9597 - iou_score: 0.9227 - val_loss: 0.4626 - val_precision: 0.8930 - val_recall: 0.9173 - val_f1-score: 0.9042 - val_iou_score: 0.8260\n",
      "Epoch 32/100\n",
      "267/267 [==============================] - 515s 2s/step - loss: 0.1823 - precision: 0.9571 - recall: 0.9638 - f1-score: 0.9604 - iou_score: 0.9239 - val_loss: 0.4574 - val_precision: 0.8979 - val_recall: 0.9145 - val_f1-score: 0.9055 - val_iou_score: 0.8285\n",
      "Epoch 33/100\n",
      "267/267 [==============================] - 503s 2s/step - loss: 0.1812 - precision: 0.9569 - recall: 0.9641 - f1-score: 0.9604 - iou_score: 0.9239 - val_loss: 0.4512 - val_precision: 0.9092 - val_recall: 0.9111 - val_f1-score: 0.9096 - val_iou_score: 0.8353\n",
      "Epoch 34/100\n",
      "266/267 [============================>.] - ETA: 1s - loss: 0.1781 - precision: 0.9577 - recall: 0.9648 - f1-score: 0.9612 - iou_score: 0.9254\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "267/267 [==============================] - 523s 2s/step - loss: 0.1783 - precision: 0.9576 - recall: 0.9648 - f1-score: 0.9611 - iou_score: 0.9253 - val_loss: 0.4386 - val_precision: 0.9069 - val_recall: 0.9131 - val_f1-score: 0.9095 - val_iou_score: 0.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb3ed2c2310>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from model import build_unet\n",
    "# from data import load_dataset, tf_dataset\n",
    "from segmentation_models.losses import bce_jaccard_loss, dice_loss, JaccardLoss\n",
    "from segmentation_models.metrics import iou_score, f1_score, precision, recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from DeepLabV3p import Deeplabv3\n",
    "\n",
    "\"\"\" Hyperparamaters \"\"\"\n",
    "dataset_path = \"people_segmentation\"\n",
    "input_shape = (512, 512, 3)\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "lr = 1e-2\n",
    "# model_path = \"unet.h5\"\n",
    "# csv_path = \"data.csv\"\n",
    "\n",
    "\"\"\" Load the dataset \"\"\"\n",
    "# (train_x, train_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "# print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "# print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "# train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "# test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
    "\n",
    "\"\"\" callbacks \"\"\"\n",
    "checkpoint_filepath = '/content/Deeplabv3p_MobilenetV2_Human_Seg_000+{epoch}.h5'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_iou_score',\n",
    "    mode='max',\n",
    "    verbose = 1,\n",
    "    period = 5,\n",
    "    save_best_only=False\n",
    "    )\n",
    "\n",
    "callbacks = [\n",
    "    model_checkpoint_callback,\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.1, verbose=1),\n",
    "#     CSVLogger(csv_path),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "]\n",
    "\n",
    "\"\"\" steps per epochs \"\"\"\n",
    "train_steps = len(train_x)//batch_size\n",
    "if len(train_x) % batch_size != 0:\n",
    "    train_steps += 1\n",
    "\n",
    "test_steps = len(test_x)//batch_size\n",
    "if len(test_x) % batch_size != 0:\n",
    "    test_steps += 1\n",
    "\n",
    "print(train_steps, test_steps)\n",
    "\n",
    "\n",
    "\"\"\" Model training \"\"\"\n",
    "ls = dice_loss + bce_jaccard_loss\n",
    "metrics = [precision, recall, f1_score, iou_score] \n",
    "\n",
    "model = Deeplabv3(weights='cityscapes', input_tensor=None, input_shape=(512,512,3), classes=1, \n",
    "                  backbone= 'mobilenetv2', #'xception'\n",
    "                  OS=16, alpha=1., activation='sigmoid')\n",
    "\n",
    "for layer in model.layers:\n",
    "  # if layer.name == \"decoder_conv0_depthwise\":\n",
    "  #   break\n",
    "  # else:\n",
    "  layer.trainable = True\n",
    "# for layer in model.layers:\n",
    "#   print(layer.name,layer.trainable)\n",
    "\n",
    "model.compile(\n",
    "    loss=ls,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    metrics=metrics\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=test_steps,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYMMboQpOdmZ"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "cellView": "form",
    "id": "j5pmoDJqKb1C"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "model = Deeplabv3(weights='cityscapes', input_tensor=None, input_shape=(512,512,3), classes=1, \n",
    "                  backbone= 'mobilenetv2', #'xception'\n",
    "                  OS=16, alpha=1., activation='sigmoid')\n",
    "# from tensorflow.keras.models import load_model\n",
    "model.load_weights('/content/Deeplabv3p_MobilenetV2_Human_Seg_000+30.h5')\n",
    "model.compile(\n",
    "    loss=ls,\n",
    "    # optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miwbmm7XaJH0",
    "outputId": "84c805fe-db58-4450-94db-8e6d9d3e09fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('SJ.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "img = img/255.0\n",
    "img = img.astype(np.float32)\n",
    "img = img.reshape(1, 512, 512, 3)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBt3LmPmIJ3y",
    "outputId": "39d801ec-bf06-4ba2-fc2c-b629984a3f9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = pred.reshape(512, 512)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAM3Mg8eIhE2",
    "outputId": "b58a1cee-ae47-465f-ba80-2e5a7290cc4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "pred = pred * 255\n",
    "pred = pred.astype(np.uint8)\n",
    "cv2.imwrite('pred_SJ.jpg',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySJuNUWFJOOi",
    "outputId": "2f209191-b390-4597-cc0d-8c8912b7637c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('SJ.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "pred = np.dstack([pred, pred, pred])\n",
    "overlay = cv2.addWeighted(img, 0.6, pred, 0.4, 0)\n",
    "cv2.imwrite('overlay_SJ.jpg',overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "cellView": "form",
    "id": "Q4YL0qVQJ7NC"
   },
   "outputs": [],
   "source": [
    "#@title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-waejeVKeZu",
    "outputId": "d8b4aae3-b5f0-4485-a6d0-43f5be3e9f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('75805310.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "img = img/255.0\n",
    "img = img.astype(np.float32)\n",
    "img = img.reshape(1, 512, 512, 3)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ve9SRlyVKeZw",
    "outputId": "7665ef13-96f1-4469-9da7-61e8e9db2889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = pred.reshape(512, 512)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dBwDclaKeZx",
    "outputId": "d20bd29c-b78e-4757-f81f-de871620292b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "pred = pred * 255\n",
    "pred = pred.astype(np.uint8)\n",
    "cv2.imwrite('pred_75805310.jpg',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtJXKc0KKeZy",
    "outputId": "a045aae3-4251-4d1c-8aa5-71c07f19f3a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('75805310.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "pred = np.dstack([pred, pred, pred])\n",
    "overlay = cv2.addWeighted(img, 0.6, pred, 0.4, 0)\n",
    "cv2.imwrite('overlay_75805310.jpg',overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "cellView": "form",
    "id": "zn8IOOmoKk5b"
   },
   "outputs": [],
   "source": [
    "#@title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOneVH6_K9qE",
    "outputId": "8a03a134-65a7-4ee9-f6bd-f702e4d2517c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('oldestman.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "img = img/255.0\n",
    "img = img.astype(np.float32)\n",
    "img = img.reshape(1, 512, 512, 3)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7nQGs10K9qF",
    "outputId": "59eb9a6c-c1bb-420d-e6a0-ba6e75c19c63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = pred.reshape(512, 512)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBwv_u0rK9qG",
    "outputId": "392caf30-60f2-4ad0-fa6f-9c057eac0cfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "pred = pred * 255\n",
    "pred = pred.astype(np.uint8)\n",
    "cv2.imwrite('pred_oldestman.jpg',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQYQPIL1K9qG",
    "outputId": "23adbd3c-2adc-46a7-c8de-30a11a584e3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('oldestman.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "pred = np.dstack([pred, pred, pred])\n",
    "overlay = cv2.addWeighted(img, 0.6, pred, 0.4, 0)\n",
    "cv2.imwrite('overlay_oldestman.jpg',overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cellView": "form",
    "id": "-CQMRzl-Ml70"
   },
   "outputs": [],
   "source": [
    "#@title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afgSBaEMMmi-",
    "outputId": "b47098b8-563c-4ac6-c41a-ff7ca13a2c95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('multiple.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "img = img/255.0\n",
    "img = img.astype(np.float32)\n",
    "img = img.reshape(1, 512, 512, 3)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRjpaj4hMmi_",
    "outputId": "4303462c-2744-4b7d-cf9a-94314fa4c915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = pred.reshape(512, 512)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_z2rJG1MmjA",
    "outputId": "3ba37fa2-368a-4ef7-903e-643acce3f68b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "pred = pred * 255\n",
    "pred = pred.astype(np.uint8)\n",
    "cv2.imwrite('pred_multiple.jpg',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9nGMmSVMmjA",
    "outputId": "bc78db3d-7223-4330-fef0-8018c86f88cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('multiple.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "pred = np.dstack([pred, pred, pred])\n",
    "overlay = cv2.addWeighted(img, 0.6, pred, 0.4, 0)\n",
    "cv2.imwrite('overlay_multiple.jpg',overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "cellView": "form",
    "id": "eE5olQSRMszz"
   },
   "outputs": [],
   "source": [
    "#@title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPkuvD2HNYy3",
    "outputId": "66d6cc34-aa4d-4b6c-f2a0-9c16d084d0b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('2.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "img = img/255.0\n",
    "img = img.astype(np.float32)\n",
    "img = img.reshape(1, 512, 512, 3)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9k2h56iNYy5",
    "outputId": "78ab7fbc-1127-4672-b92c-471fe04d694c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = pred.reshape(512, 512)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7X8mX-sNYy7",
    "outputId": "8cd122e3-0cea-493f-bd88-75dc08ef1c8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "pred = pred * 255\n",
    "pred = pred.astype(np.uint8)\n",
    "cv2.imwrite('pred_2.jpg',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyfJIUjGNYy8",
    "outputId": "3ee7bc81-1ad8-4322-aabe-b2a680e97ef4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "img = cv2.imread('2.jpg')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "pred = np.dstack([pred, pred, pred])\n",
    "overlay = cv2.addWeighted(img, 0.6, pred, 0.4, 0)\n",
    "cv2.imwrite('overlay_2.jpg',overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "g-3G0dwWNcAm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "fB_PzJ2Ku9No"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "O-I9tYA2u9LQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Y8BL5GZ3u9I7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eQK5L6kHu9Gy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "foTPbXBxu9ER"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "I2uFJ-TIu9B4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5LqlrFfFu8_h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "LlkjGbc0u88_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "IJM3mm_6u86V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "FXOsYlRLu832"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
